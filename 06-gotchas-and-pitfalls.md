# RK3576 "陷阱" 与注意事项

## 1. ⚠️ 模型转换：仅限 x86 Linux
- **问题**: 你**不能**在 Rock 4D 开发板本身 (ARM64) 上转换模型 (`.onnx` -> `.rknn` 或 `.safetensors` -> `.rkllm`)。
- **问题**: 你**不能**在 macOS 上直接转换模型 (除非使用 Docker/VM)。
- **解决方案**: 
  - 使用专用的 x86 Linux 机器 (Ubuntu 20.04/22.04)。
  - 在 Mac 上使用 Docker (确保 docker-compose 中设置 `platform: linux/amd64`)。
  - 使用运行 Ubuntu 的虚拟机 (VMware Fusion / Parallels / UTM)。
  - **不要尝试在 ARM 板上 pip install rknn-toolkit2 进行转换。这行不通。**

## 2. ⚠️ NPU 核心数不匹配
- **问题**: 许多教程和脚本是为 RK3588 (3 个 NPU 核心) 编写的。
- **事实**: RK3576 只有 **2 个 NPU 核心**。
- **结果**: 复制粘贴的代码可能会失败，报错 "Invalid NPU Core" 或 "Resource Busy"。
- **修复**: 初始化时，始终设置 `target_platform="rk3576"` 和 `core_mask=RKNN_NPU_CORE_0_1` (或取决于 API 版本的类似设置)。

## 3. ⚠️ RKLLM 运行时版本地狱
- **问题**: `.rkllm` 模型文件格式在版本之间会发生变化。
- **症状**: "Load model failed" (加载模型失败) 或段错误 (segfault)。
- **规则**: 如果你使用 Toolkit v1.1.4 转换，你必须使用 Runtime v1.1.4。
- **建议**: 工具包和运行时都坚持使用**最新版本 (v1.2.3)**。

## 4. ⚠️ 散热与降频
- **问题**: LLM 推理会使 NPU 和 CPU 满载。
- **症状**: 5-10 分钟后性能下降。
- **修复**: **主动散热 (风扇) 是必须的。** 不要依赖被动散热片进行 LLM 负载工作。

## 5. ⚠️ SD 卡 vs eMMC vs NVMe
- **问题**: 从慢速 SD 卡加载 4GB 模型需要 30 秒以上。
- **影响**: 冷启动延迟极其糟糕。
- **修复**: 使用 eMMC 模块或 NVMe SSD (如果有 M.2 插槽/转接)。
- **基准测试**: SD 卡 (~20-40 MB/s) vs eMMC (~150 MB/s) vs NVMe (~1000+ MB/s)。

## 6. ⚠️ 内存碎片
- **问题**: 8GB 内存是共享的。如果你频繁加载/卸载模型，可能会耗尽 NPU 缓冲区的连续内存。
- **修复**: 每天重启或小心管理内存。如果需要 (高级)，在内核启动参数中预留 CMA (连续内存分配器)。

## 7. ⚠️ 量化精度
- **问题**: W8A8 是标准，但 W4A16 是较大模型所需的。
- **权衡**: W4A16 可能会降低较小模型 (<3B) 的推理质量。
- **测试**: 部署前如果可能，始终基准测试困惑度 (PPL)。
